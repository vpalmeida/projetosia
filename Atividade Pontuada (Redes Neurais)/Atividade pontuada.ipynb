{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade pontuada: Redes Neurais, teoria\n",
    "    \n",
    "\n",
    "\n",
    "Realizar a leitura das páginas 127 a 158 do livro \"Inteligência Artificial Aplicada: uma abordagem introdutória\":\n",
    "\n",
    "https://plataforma.bvirtual.com.br/Leitor/Publicacao/161682/\n",
    "\n",
    "Assistir ao vídeo:\n",
    "https://www.youtube.com/watch?v=UaqzXSAaqkw\n",
    "\n",
    "Responder as questões de 4 a 18 das páginas 160 a 162. \n",
    "\n",
    "A entrega deve ser realizada por arquivo em um dos seguintes formatos: PDF, DOCX, IPYNB.\n",
    "\n",
    "Prazo: 18/10/2020 as 23h.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento de uma rede neural vai depender da arquitetura adotada na construção da rede. Ao longo dos anos, têm-se desenvolvido diversos métodos e/ou algorítmos de treinamento, entre os quais o mais utilizado é o algoritmo de retropropagação (backpropagation) que aplica a informação do erro na atualização dos pesos.\n",
    "\n",
    "Entre as modalidades de treinamento, podemos citar 5 mais importantes:\n",
    "\n",
    "1 -> Aprendizagem mediante correção de erros - A informação doerro é utilizada para modificar os pesos sinápticos.\n",
    "\n",
    "2 -> Aprendizagem baseada em memória - Armazena-se um grande número de exemplos de entrada e saída e uma amostra é comparada com sua vizinhança, a fim de que se identifique a que classe pertence.\n",
    "\n",
    "3 -> Aprendizagem hebbiana - Emprega uma regra associativa, que aumenta a força dos pesos positivamente correlacionados, ou diminui a daqueles negativamente correlacionados.\n",
    "\n",
    "4 -> Aprendizagem competitiva - Os neurônios competem entre si para tornarem-se ativos. O vencedor estará ativo durante certo instante.\n",
    "\n",
    "5 -> Aprendizagem de Boltzmann - Os neurônios constituem uma estrutura recorrente e operam de uma maneira binária, controlados por uma função de energia. A atualização dos pesos ocorre por correlação, operando em duas condições: uma presa, em que os neurônios visíveis estão todos presos a estados específicos determinados pelo ambiente; e outra livre, em que todos os neurônios podem operar livremente.\n",
    "\n",
    "O treinamento/aprendizagem ainda pode ser caracterizada como:\n",
    "    supervisionada: em que há o feedback que retorna à rede para orientar o treinamento e\n",
    "    não-supervisionada: a rede aprende de forma auto-organizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma rede neural apresenta, assim como o cérebro humano, a capacidade de generalização baseada  no  conhecimento  aprendido.  Isto  significa  que  uma  rede  neural  consegue  produzir  saídas  adequadas  para  entradas  não  observadas no seu processo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Perceptron é um modelo matemático de um neurônio biológico. Enquanto nos neurônios reais o dendrito recebe sinais elétricos dos axônios de outros neurônios, no Perceptron estes sinais elétricos são representados como valores numéricos. Nas sinapses entre dendritos e axônio, os sinais elétricos são modulados em várias quantidades. Isso também é modelado no Perceptron multiplicando cada valor de entrada por um valor chamado peso. Um neurônio real dispara um sinal de saída somente quando a força total dos sinais de entrada excede um certo limiar. Nós modelamos esse fenômeno em um Perceptron calculando a soma ponderada das entradas para representar a força total dos sinais de entrada e aplicando uma função de ativação na soma para determinar sua saída. Tal como nas redes neurais biológicas, esta saída é alimentada em outros Perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento de uma rede MLP insere-se no contexto de aprendizado de máquina supervisionado, em que cada amostra de dados utilizada apresenta um rótulo informando a que classificação ela se encaixa. Por exemplo, uma imagem de um cachorro contém um rótulo informando que aquilo é um cachorro. Assim, a ideia geral é fazer com que a rede aprenda os padrões referentes a cada tipo de coisa (cada classe), assim, quando uma amostra desconhecida for fornecida à rede, ela seja capaz de estabelecer a qual classe tal amostra pertence.\n",
    "\n",
    "O algoritmo de retropropagação do erro é o processo supervisionado mais utilizado para treinamento de redes  neurais MLP. Uma versão macro do seu funcionamento apresenta a seguinte estrutura:\n",
    "\n",
    "    1 - Inicialização dos pesos e parâmetros da rede neural com valores aleatórios.\n",
    "    2 - Apresentar um vetor x na entrada da rede neural e observar o vetor de saída y gerado.\n",
    "    3 - Comparar o vetor de saída y  gerado pela rede com o vetor d de resposta desejada.\n",
    "    4 - Adaptar os pesos w através do algoritmo recursivo: \n",
    "        a - Calcular, para cada camada da rede, começando da camada de saída e seguindo em \n",
    "        direção a camada de entrada: wij(t+1) = wij(t) + ηδj x’i onde:\n",
    "            i. wij(t) é o valor do peso sináptico do neurônio j no tempo t.\n",
    "            ii. η é um termo de ganho, que permite regular a velocidade dos ajustes.\n",
    "            iii. Se o neurônio pertencer a camada de saída da rede neural temos: \n",
    "                δj = yj(1 - yj)(dj - yj) onde  j representa a saída desejada e yj representa a \n",
    "                saída real.\n",
    "            iv. Se o neurônio pertencer a uma camada oculta temos:\n",
    "                δj =x’j (1 - x’j)∑SkWjk onde k representa todos os elementos processadores \n",
    "                acima de j.\n",
    "    5 - Voltar ao passo 2 e repetir procedimento até que a condição de parada seja alcançada.\n",
    "    \n",
    "Outro algoritmo bastante utilizado é o do Mínimo Quadrado Médio criado por Widrow e Hoff e de fácil implementação. Esse algoritmo consiste em calcular o erro de classificação para, na sequência, utilizar uma fração desse erro para o ajuste dos pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A taxa de aprendizagem é o parâmetro que regula a atualização dos pesos sinápticos. Se a taxa for pequena o treinamento   demorará mais e, dependendo dos valores de inicialização dos pesos, o processo de treinamento pode ficar preso em um mínimo  local. Se for muito grande as variações nos pesos poderão oscilar impedindo que o mínimo global seja alcançado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifidamente, suponhamos que existem dois valores de entrada, x e y para um certo Perceptron P. Vamos definir os pesos de x e y, como sendo A e B, respectivamente. A soma ponderada pode ser representada como: A x + B y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções de ativação são um elemento extremamente importante das redes neurais artificiais. Elas basicamente decidem se um neurônio deve ser ativado ou não. Ou seja, se a informação que o neurônio está recebendo é relevante para a informação fornecida ou deve ser ignorada. Elas permitem que pequenas mudanças nos pesos e bias causem apenas uma pequena alteração no output.\n",
    "\n",
    "A função de ativação é a transformação não linear que fazemos ao longo do sinal de entrada. Esta saída transformada é então enviada para a próxima camada de neurônios como entrada. Quando não temos a função de ativação, os pesos e bias simplesmente fazem uma transformação linear. Uma equação linear é simples de resolver, mas é limitada na sua capacidade de resolver problemas complexos. Uma rede neural sem função de ativação é essencialmente apenas um modelo de regressão linear. A função de ativação faz a transformação não-linear nos dados de entrada, tornando-o capaz de aprender e executar tarefas mais complexas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cálculo do erro pode ser dividido em duas categorias:\n",
    "\n",
    "Erro individual: pode ser representado pela fórmula ei=(oi - fi), onde \"ei\" corresponde à diferença entre a saída desejada \"oi\" e a saída calculada após a ativação \"fi\".\n",
    "\n",
    "Erro global: consiste em uma medida de desempenho global do perceptron, que pode ser calculada pela média quadrática dos erros individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A afirmação de que um conjunto de amostras é separável linearmente é uma condição básica para o funcionamento do perceptron.\n",
    "\n",
    "Isso significa que os padrões ou as amostras pertencentes a classes distintas devem estar suficientemente separados para que uma correta classificação seja possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um perceptron poderia classificar o conjunto de amostras do enunciado do exercício, já que o vetor de valores de saída resultantes para as classes A e B são completamente distintos.\n",
    "\n",
    "    Classe A = (1,2)\n",
    "    Classe B = (7,9,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada oculta de uma rede neural, são todas as camadas cujos neurônios não fazem parte da entrada ou da saída. A camada oculta relaciona as unidades de entrada com as unidades geradoras de saída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As respostas para as afirmativas são, respectivamente: V, F, V, F, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entradas\n",
    "w = 0.45\n",
    "w2 = 0.10\n",
    "w0 = -1\n",
    "\n",
    "#Amostras e Pesos X1 e X2\n",
    "Amostras = []\n",
    "Amostras.append([1,8,3,'','',1,'',''])\n",
    "Amostras.append([2,1,1,'','',-1,'',''])\n",
    "Amostras.append([3,4,2,'','',-1,'',''])\n",
    "Amostras.append([4,2,1,'','',1,'',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_amostras(Lista):\n",
    "    for index, value in enumerate(Lista):\n",
    "        print('Amostra: ', Lista[index][0])\n",
    "        print('X1: ', Lista[index][1])\n",
    "        print('X2: ', Lista[index][2])\n",
    "        print('d: ', Lista[index][3])\n",
    "        print('f: ', Lista[index][4])\n",
    "        print('o: ', Lista[index][5])\n",
    "        print('Classe: ', Lista[index][6])\n",
    "        print('e: ', Lista[index][7], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 8, 3, 2.9000000000000004, '', 1, '', ''],\n",
       " [2, 1, 1, -0.45, '', -1, '', ''],\n",
       " [3, 4, 2, 1.0, '', -1, '', ''],\n",
       " [4, 2, 1, 0.0, '', 1, '', '']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra:  1\n",
      "X1:  8\n",
      "X2:  3\n",
      "d:  2.9000000000000004\n",
      "f:  \n",
      "o:  1\n",
      "Classe:  \n",
      "e:   \n",
      "\n",
      "Amostra:  2\n",
      "X1:  1\n",
      "X2:  1\n",
      "d:  -0.45\n",
      "f:  \n",
      "o:  -1\n",
      "Classe:  \n",
      "e:   \n",
      "\n",
      "Amostra:  3\n",
      "X1:  4\n",
      "X2:  2\n",
      "d:  1.0\n",
      "f:  \n",
      "o:  -1\n",
      "Classe:  \n",
      "e:   \n",
      "\n",
      "Amostra:  4\n",
      "X1:  2\n",
      "X2:  1\n",
      "d:  0.0\n",
      "f:  \n",
      "o:  1\n",
      "Classe:  \n",
      "e:   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LETRA A\n",
    "for index, value in enumerate(Amostras):\n",
    "    Amostras[index][3] = (w*Amostras[index][1])+(w2*Amostras[index][2]+w0)\n",
    "\n",
    "exibir_amostras(Amostras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questão 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
