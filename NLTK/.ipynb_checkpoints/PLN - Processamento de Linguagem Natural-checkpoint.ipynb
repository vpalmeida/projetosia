{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de Linguagem Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento de Linguagem Natural (PLN daqui em diante) é uma área de estudo dentro da Inteligência Artificial utilizada para resolver problemas, normalmente voltada para a criação de ferramentas práticas e utilizadas no nosso dia a dia. Não imaginamos mais nossas vidas sem Google. Usamos os assistentes pessoais em nossos smartphones (Siri), para atividades básicas, como fazer uma ligação telefônica. Usamos cada vez mais os filtros de spam. Empresas buscam analisar os sentimentos dos clientes em relação a produtos ou serviços. Sempre que escrevemos um texto, clicamos no botão do corretor ortográfico para checar se cometemos algum erro de digitação ou mesmo gramatical e podemos fazer isso em diversos idiomas. Existem muitos exemplos de como o PLN já está sendo usado há um bom tempo. Talvez você não saiba, mas você utiliza PLN em aplicações como:\n",
    "\n",
    "    Corretores Ortográficos (Microsoft Word)\n",
    "    Engines de Reconhecimento de Voz (Siri, Google Voice)\n",
    "    Classificadores de Spam\n",
    "    Mecanismos de Busca (Google, Bing)\n",
    "\n",
    "O Processamento de Linguagem Natural  é um campo da ciência da computação, inteligência artificial e computação linguística cujo foco está na interação entre computadores e linguagem (natural) humana. São muitos os desafios envolvidos em fazer o computador compreender o significado na geração de linguagem natural. Essencialmente, PLN é a aplicação de aspectos teóricos da linguagem a aplicações de computador.\n",
    "\n",
    "O desenvolvimento de aplicações PLN é sempre um desafio, pois o computador espera que a linguagem humana seja precisa, não ambígua e altamente estruturada. Mas como sabemos, normalmente é exatamente o contrário. A linguagem humana não é precisa, é frequentemente ambígua, sendo ainda recheada de gírias, dialetos regionais, contexto social e agora abreviações de linguagem, deste novo mundo de redes sociais em que vivemos.\n",
    "\n",
    "Atualmente a PLN é baseada em Machine Learning, um subconjunto da Inteligência Artificial, que examina e utiliza padrões em dados para melhor compreender a linguagem natural. O PLN é a aplicação de computadores em diferentes nuances da linguagem, para construir aplicações que sejam capazes de processar a linguagem humana e extrair informação relevante, como análise de sentimentos, por exemplo. Em uma analogia simples, PLN é como ensinar uma linguagem a uma criança. Primeiro começamos ensinando as palavras, então as sentenças, a forma gramatical, sentenças gramaticalmente corretas e então a linguagem passa a ser natural para a criança. Todas essas tarefas foram traduzidas para linguagem computador, para que as mesmas atividades pudessem ser ensinadas as máquinas.\n",
    "\n",
    "Conceitos como tokezination, chunking, parsing, etc..são ainda um grande desafio para os computadores. Se nem os seres humanos entendem si próprios, como ensinar isso as máquinas, não é mesmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem Clássica do Processamento de Linguagem Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tradicionalmente, o trabalho no Processamento de Linguagem Natural é decomponível em várias etapas, refletindo as distinções linguísticas teóricas traçadas entre sintaxe, semântica e pragmática.\n",
    "\n",
    "Essa tentativa de correlação entre uma distinção estratificada (sintaxe, semântica e pragmática) e uma distinção em termos de granularidade (oração versus discurso) às vezes causa alguma confusão ao pensar sobre as questões envolvidas no processamento da linguagem natural. E é amplamente reconhecido que, em termos reais, não é tão fácil separar o processamento da linguagem em caixas correspondentes a cada um dos estratos. No entanto, tal separação serve como uma ajuda pedagógica útil e também constitui a base para modelos arquitetônicos que tornam a tarefa de análise de linguagem natural mais gerenciável do ponto de vista da engenharia de software [Dale, 2010].\n",
    "\n",
    "Não obstante, a distinção em três partes englobando sintaxe, semântica e pragmatismo apenas serve, na melhor das hipóteses, como um ponto de partida quando se considera o processamento de textos de linguagem natural real.  Uma decomposição desse processo em mais estágios é útil ao se levar em conta o atual estado da arte em combinação com os dados de linguagem reais.\n",
    "\n",
    "Em geral, Processamento de Linguagem Natural, temos as seguintes etapas:\n",
    "\n",
    "    Texto -> Tokenização -> Análise Léxica -> Análise Sintática -> Análise Semêntica -> Análise Pregmática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenização, em suma, quebra a sequência de caracteres em um texto localizando o limite de cada palavra, ou seja, os pontos onde uma palavra termina e outra começa [Palmer, 2010]. Para fins de linguística computacional, as palavras assim identificadas são frequentemente chamadas de tokens. As sequências de caracteres delimitadas não são necessariamente os tokens requiridos para processamento adicional, devido tanto à natureza ambígua dos sistemas de escrita como à gama de convenções de tokenização requeridas por diversas aplicações [Palmer, 2010]. Em linguagens não segmentadas, tais como o chinês e o tailandês, as palavras são escritas em sucessão com nenhuma indicação de limite de palavras.  A tokenização das linguagens não segmentadas, portanto, requer informação léxica e morfológica adicional. Em relação à tokenização em linguagens delimitadas por espaço, a maioria das ambiguidades existem entre o uso de sinais de pontuação, tais como ponto final, vírgulas, aspas,  apóstrofos e hífens, uma vez que o mesmo sinal de pontuação pode servir para diferentes funções em uma mesma sentença. Em vários casos, esses sinais devem ser tratados como um token separado. Por outro lado, existem casos em que esses caracteres devem ser “anexados” a outro token. Por exemplo, no português, as abreviações devem conter os pontos, tais como Av. (avenida), Sr. ou Sra. (senhorou senhora) e Dr. ou Dra. (doutor ou doutora). As abreviações são usadas na linguagem escrita para denotar uma forma mais curta da palavra. Em vários casos, as abreviações são escritas como uma sequência de caracteres terminadas com um ponto final, assim como mostrados nos exemplos citados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Léxica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise léxica é a análise a nível de palavras. Uma palavra pode ser pensada de duas maneiras: como uma sequência de caracteres no texto em execução, como por exemplo, o verbo ENTREGAR, ou como um objeto mais abstrato que é o termo principal para um conjunto de sequência de caracteres (palavras), sendo o  verbo  ENTREGAR  o  objeto  abstrato,  ou \"lemma\",  do  conjunto  {entrega, entregador, entregando, entregue}. A tarefa básica da análise léxica é relacionar variantes morfológicas aos seus \"lemmas\", que nada mais são do que as formas canônicas das palavras, ou a forma em que as palavras se encontram no dicionário.\n",
    "\n",
    "Para tal é necessário utilizar um dicionário de \"lemmas\" em que eles se encontram junto de suas informações semânticas e sintáticas invariantes [Hippisley,  2010]. A lematização é utilizada de diferentes formas, as quais dependem da tarefa a ser realizada pelo sistema de processamento de linguagem natural. A utilização dos \"lemmas\" é feita, por exemplo, utilizando o verbo ENTREGAR: ENTRE-GAR + {3ª pessoa do singular, presente}, então, todas as palavras são formadas a partir do \"lemma\" retirando o sufixo de conjugação. Segundo [Hippisley, 2010], a análise léxica tem dois lados: o mapeamento da palavra até o seu \"lemma\", chamado de parsing side e o outro lado é o mapeamento do \"lemma\" para a palavra, chamado de geração morfológica. Na recuperação de informação o parsing e o generation servem diferentes propósitos. Para a criação automática da lista de termos chave, faz  sentido ter a noção das variantes sobre um único \"lemma\". Este  propósito é alcançado na prática durante o stemming, uma operação de pré processamento de textos onde palavras mais complexas morfologicamente são identificadas, decompondo em seu stem invariante, ou melhor, na forma canônica do \"lemma\" e seus afixos, e no final os afixos são deletados. O stem, portanto, é o chamado radical da palavra. Por exemplo, ainda sobre o verbo ENTREGAR, o lemma é ENTREGAR e ostemé ENTREG, pois a partir do stem podem ser criadas outras palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Sintática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria dos trabalhos na área de PLN pressupoem que a unidade básica de análise de significado é a frase:  uma frase expressa uma proposição, uma ideia ou um pensamento, além de dizer algo sobre o mundo real ou imaginário. Extrair o significadode uma frase é, portanto, uma questão crucial. As frases não são, no entanto, apenas umasequência linear de palavras e, por isso, é amplamente reconhecido que para realizar essatarefa requer uma análise fiel de cada frase, as quais determinam suas estruturas de umamaneira ou de outra.  Nas abordagens de PLN baseadas em linguística generativa, isso é geralmente levado a determinar a estrutura sintática ou gramatical de cada frase. Uma das formas de se representar a análise sintática é por meio de gramáticas e árvores sintáticas.\n",
    "\n",
    "A gramática é composta pelos chamados de símbolos pré terminais, que se decompõem sempre em uma produção, correspondentes aos termos léxicos. \n",
    "\n",
    "A árvore sintática é a representação de todas as etapas na derivação da frase a partir do nó raiz.  Isso significa que cada nó interno na árvore representa a aplicação de uma regra da gramática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Semântica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando  se  leva  em  consideração  textos  longos, aplicações de PLN específicas  podem incluir recuperação de informação, extração de informação, sumarização de textos, mineração de dados e tradução para linguagem de máquina e auxiliares de tradução. A análise semântica também é útil para vários textos menores. Além disso, a análise semântica também tem uma alta relevância nos esforços da comunidade científica para melhorar as ontologias existentes na Web e os sistemas de representação de conhecimento [Goddardand Schalley, 2010].\n",
    "\n",
    "De acordo com [Poesio, 2000], o objetivo final para humanos, bem como para sistemas de PLN, é entender o enunciado – o qual, dependendo das circunstâncias, pode significar a incorporação de informações providas pelo enunciado dentro de sua própria base de conhecimento ou geralmente executando alguma ação em resposta à isso.  “Entender” um enunciado é um processo complexo que depende do resultados das análises anteriores (léxica e sintática), assim como das informações léxicas, contexto e do raciocínio comum.\n",
    "\n",
    "Na linguística, a análise semântica refere-se à análise do significado das palavras, expressões fixadas, sentenças inteiras e enunciados no contexto [Goddard and Schalley,2010]. Na prática, isso significa traduzir as expressões originais em um tipo de metalinguagem. Em termos gerais, a evidência primária para a linguística semântica vem das interpretações do orador nativo no uso das expressões no contexto (incluindo suas deduções e implicações), padrões de uso, colocação e frequência, que são detectáveis usando técnicas de linguísticas em Córpus diversos.\n",
    "\n",
    "Um requerimento frequentemente identificado para as análises semânticas em PLN é em título de resolução de ambiguidade. Do ponto de vista de uma máquina, vários enunciados humanos estão abertos à multiplas interpretações, pois as palavras podem ter mais de um significado (ambiguidade léxica) ou porque certas palavras, tais como quantificadores, modais ou operadores negativos pode ser aplicadas em diferentes trechos de texto (ambiguidade escopal), ou ainda porque a referência pretendida de pronomes ou outras se referindo à expressões podem não ser fáceis de entender (ambiguidade referencial).\n",
    "\n",
    "Em relação às ambiguidades léxicas, é normal a distinção entre homônimos (diferentes palavras com a mesma forma, tanto o som quanto a escrita, como por exemplo, manga (fruta) e manga (de camisa), ou concerto (sessão musical) e conserto (reparo)) e polissemia (diferentes sentidos para a mesma palavra, por exemplo, “mão suja” e “passaram a mão”).  Ambos esses fenômenos são problemáticos em PLN, mas a polissemia apresenta maiores problemas, pois as diferenças de significado em questão, além das diferenças sintáticas associadas e outras diferenças formais são tipicamente mais sutis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Pragmática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo [Muller, 2003], a análise pragmática foge à estrutura de apenas uma frase, uma vez que ela busca nas outras frases a compreensão do texto que falta àquela frase em análise. Não existem estruturas pré-definidas que atendam a uma representação adequada de problemas de referências pronomiais, como por exemplo, os pronomes “la”, “seu” e “o” na frase “João pegou a rosa. Ao pegá-la,seu espinho o espetou”, coerência textual e análise do discurso. Por outro lado, as estruturas mais utilizadas na análise pragmática são as gramáticas baseadas em casos, que são gramáticas semânticas não-terminais para formar padrões, onde caso uma dada frase encaixe na construção padrão, ela poderá ser reconhecida dentro de um contexto [Carbonell and Hayes, 1987, Minker, 1998, Barker,1998].\n",
    "\n",
    "Como exemplo de algoritmo utilizado na análise pragmática, [Muller, 2003] discorre sobre um algoritmo proposto por [Lappin and Leass, 1994], de resolução de referências pronomiais. Neste algoritmo, são atribuídos pesos aos pronomes encontrados em frases. Esses pesos são chamados de “valores de saliência” e são atribuídos aos sujeitos encontrados na mesma frase ou nas frases precedentes. Quanto mais próximo do pronome estiver o sujeito, maior será o valor a ele atribuído como referência ao pronome. Após ser atribuído os pesos aos sujeitos de referência encontrados, retiram-se aqueles que não combinam em gênero e número e são levadas em conta outras características como o tipo de pronome, se a frase tem objeto indireto ou advérbio, entre outros fatores.\n",
    "\n",
    "Há ainda muitos outros algoritmos citados na literatura acerca de resolução de referências pronomiais [Mitkov, 1998, Ng and Cardie, 2002, Haghighi and Klein, 2009], porém, a maioria é dependente de uma estrutura sintática previamente determinada ou pouco flexível a diferentes construções frasais. Por esta dificuldade de ser identificada a construção frasal é que tem sido cada vez mais utilizadas estruturas de preenchimento como casos para análise pragmática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabalhar com PLN existem diversas ferramentas open-source disponíveis, tais como:\n",
    "\n",
    "    GATE (General Architecture for Text Engineering) – https://gate.ac.uk/\n",
    "    Mallet (Machine Learning for Language Toolkit) – http://mallet.cs.umass.edu/\n",
    "    OpenNLP – https://opennlp.apache.org/\n",
    "    UIMA – https://uima.apache.org/external-resources.html\n",
    "    Genism – https://radimrehurek.com/gensim/\n",
    "    Natural Language Toolkit (NLTK) – http://www.nltk.org/\n",
    "\n",
    "Muitas são também robustas e possuem uma variedade de ferramentas disponíveis. Mas quando falamos de simplicidade e facilidade de uso, o NLTK é a primeira opção. O NLTK é uma ótima opção para quem está aprendendo PLN, por sua facilidade de uso e por ter sido escrito em linguagem Python, uma das linguagens mais populares atualmente.\n",
    "\n",
    "O NLTK é uma biblioteca da linguagem Python para Processamento de Linguagem Natural e Text Analytics, que foi originalmente criado para o ensino de PLN, mas que vem sendo amplamente adotado no desenvolvimento de aplicações de PLN em geral.\n",
    "\n",
    "O módulo NLTK é um kit de ferramentas, destinado a ajudar com Processamento de Linguagem Natural (PLN). O NLTK será útil para separar as sentenças em um parágrafo, separar as palavras dentro de cada sentença, reconhecer padrões no texto e criar modelos de classificação que permitam, por exemplo, realizar análise de sentimentos em um conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fontes de Pesquisa\n",
    "    \n",
    "    http://datascienceacademy.com.br/blog/processamento-de-linguagem-natural-python-nltk/\n",
    "    http://www.facom.ufu.br/~wendelmelo/terceiros/tutorial_nltk.pdf\n",
    "    http://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
